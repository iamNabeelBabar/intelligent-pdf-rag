# -*- coding: utf-8 -*-
"""RAG SYSTEM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-sEqSqg_2bQutmIf1949Y-wp94fSWt-K

# **Langchain: Reterival Augmented Generation**
"""

!pip install langchain_community

"""## **Loading the Document Using PyPDFLoader**"""

!pip install pypdf

from langchain.document_loaders import PyPDFLoader
file_path = '/content/National AI Policy Consultation Draft V1.pdf'
loader = PyPDFLoader(file_path)
pages = loader.load()

print(len(pages))

"""## **Cleaning the Pages data removing unnessary spaces**"""

cleaned_data = []
for page in pages:
  text = page.page_content
  cleaned_text = " ".join(text.split())
  page.page_content = cleaned_text
  cleaned_data.append(page)

print(len(cleaned_data))

"""# **MetaData Preprocessing and Splitting the data**"""

from langchain.docstore.document import Document

#Recursive character text splitter
from langchain_text_splitters import RecursiveCharacterTextSplitter

re_splitter = RecursiveCharacterTextSplitter(
    chunk_size = 800,
    chunk_overlap = 200
)

doc_list = []
for page in cleaned_data:
  pg_split = re_splitter.split_text(page.page_content)

  for pg_sub_split in pg_split:
    metadata = {"source": "AI policy", "page_no": page.metadata["page"] + 1}

    doc_string = Document(page_content = pg_sub_split, metadata=metadata)
    doc_list.append(doc_string)

doc_list[91]

print(len(doc_list))

"""## **Embeddings model**"""

from langchain.embeddings import HuggingFaceEmbeddings
import os

#Intialize embedding model
embed_model = HuggingFaceEmbeddings(model_name='BAAI/bge-small-en-v1.5')

"""## **Pinecone Vector Store**"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install -qU langchain-pinecone pinecone-notebooks

""" **Create a Index in Pinecone**"""

import getpass
import os

from pinecone import Pinecone

if not os.getenv("PINECONE_API_KEY"):
    os.environ["PINECONE_API_KEY"] = getpass.getpass("Enter your Pinecone API key: ")

pinecone_api_key = os.environ.get("PINECONE_API_KEY")

pc = Pinecone(api_key=pinecone_api_key)

from pinecone import ServerlessSpec

index_name = "rag-ai-policy"  # change if desired

if not pc.has_index(index_name):
    pc.create_index(
        name=index_name,
        dimension=384,
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region="us-east-1"),
    )

index = pc.Index(index_name)

"""**Pinecone credentials**"""



"""### **Data Upsertion in Pinecone**"""

from langchain_pinecone import PineconeVectorStore as langchain_pinecone
import os
os.environ["PINECONE_API_KEY"] = PINECONE_API_KEY

#Convert documents into vectors using LangPinecone
vector = langchain_pinecone.from_documents(
    doc_list,
    embed_model,
    index_name = index_name
)

"""## **Query**"""

query = "What is AI policy for students"
pinecone_results = vector.similarity_search(query, k=1)

for result in pinecone_results:
  print(result.page_content)

